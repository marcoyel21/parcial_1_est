---
title: "Fundamentos Examen Parcial 2022"
author: "Marco Ramos & Ricardo Granillo"
output: html_document
date: "2022-10-11"
---

**Entrega:** 11 de octubre antes de las 16:00 horas, por correo electrónico con el título fundamentos-parcial, un solo documento por equipo.

**Instrucciones:**

* Tus respuestas deben ser claras y debes explicar 
los resultados, incluye también tus procedimientos/código de manera ordenada, y el código comentado.

* Se evaluará la presentación de resultados (calidad de las gráficas, tablas,...), revisa la sección de visualización en las notas.

* Se puede realizar individual o en parejas.

* Si tienes preguntas puedes escribirlas en el anuncio de canvas del examen.
```{r, echo=F,message=FALSE,warning=FALSE}
library(ggplot2)
library(dplyr)
library(MASS)
library(tidyverse)
library(survey)
library(srvyr)
library(rsample)
```

# Análisis exporatorio

## Series de tiempo

Consideramos la ventas semanales de un producto a lo largo de 5 años, 
transformaremos la variable de ventas utilizando el logaritmo. 

### 1. Describe que observas en la gráfica.

```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center''}
ventas <- read.csv("datos/ventas_semanal.csv")
head(ventas)
p1<-ggplot(ventas, aes(x = period, y = log(sales.kg))) + 
  geom_line(size = 0.3)+ theme_minimal()
p1
```

Lo primero que se puede notar al observar la gráfica es que existe una tendencia que podemos asociar con un componente temporal creciente, es decir se desplaza a través del tiempo "al alza" (presenta una pendiente positiva). En segunda instancia se puede observar otra tendencia que podríamos pensar pertenece al componente cíclico ya que se repite un patrón con un intervalo de periodos fijos. Dada nuestra exploración, consideramos que es viable intentar utilizar algún tipo de suavizamiento para capturar las distintos variaciones que observamos en la serie.


### 2. Utiliza un suavizador *loess* para capturar la tendencia de la serie.

```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}

mod_1 <- loess(log(sales.kg) ~ as.numeric(period), data = ventas, span = .5, degree = 1)

# calculamos el suavizador y residuales de una vez
ventas2 <- ventas %>% 
  mutate(ajuste_1 = fitted(mod_1))  %>% 
  mutate(res_1 = log(sales.kg) - ajuste_1)

p_tendency<-ggplot(ventas2, aes(x = period, y = log(sales.kg))) + 
  geom_line(size = 0.5)+  geom_line(aes(x = period, y = ajuste_1),size = 1,colour= "blue")+ theme_minimal()
p_tendency
```


El gráfico nos permite ver la forma que captura nuestro suavizador, la tendencia de la serie queda resaltada por la línea azul.


### 3. Ahora calcula los residuales de este ajuste y descríbelos


Mediante un suavizamiento más fino. Verifica que se ha estimado la mayor
parte de la tendencia, e intenta capturar la variación estacional de los 
residuales.


```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}

residual_loes_fino <- loess(res_1 ~ as.numeric(period), data = ventas2, span = .1, degree = 1)

residual_loes_ancho <- loess(res_1 ~ as.numeric(period), data = ventas2, span = 1, degree = 1)

# calculamos el suavizador y residuales de una vez
ventas2 <- ventas2 %>% 
  mutate(ajuste_res_fino = fitted(residual_loes_fino)) %>%
  mutate(ajuste_res_ancho = fitted(residual_loes_ancho)) %>%
  mutate(res_2 = res_1-ajuste_res_fino)

p_res1<-ggplot(ventas2, aes(x = period, y = res_1)) + 
  geom_line(size = 0.3)+ theme_minimal()

p_season<-ggplot(ventas2, aes(x = period, y = res_1)) + 
  geom_line(size = 0.3)+  
  geom_line(aes(x = period, y = ajuste_res_fino),size = 0.3, colour ="Blue")+ theme_minimal()

p_season+
   geom_line(aes(x = period, y = ajuste_res_ancho),size = 0.75, colour = "Green")+ theme_minimal()

```

En el gráfico podemos observar con la línea verde (centrada en cero) que ya no hay tendencia. La incorporación de esta línea nos funciona como un verificador para asegurar eliminamos la tendencia y con ello únicamente nos queda el componente cíclico de la serie.


### 4. Grafica los residuales obtenidos después de ajustar el componente estacional para estudiar la componente de mayor frecuencia.


```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}

p_res2<-ggplot(ventas2, aes(x = period, y = res_2)) + 
  geom_line(size = 0.3) + theme_minimal()
p_res2

```


El objetivo del gráfico anterior es mostrar lo que obtenemos con las dos correcciones. Nuestra gráfica nos muestra únicamente su componente aleatorio conocido como ruido blanco, confirmando el tratamiento de la serie. 


### 5. Visualiza el ajuste, genera una gráfica de páneles, en cada uno muestra una componente de la serie de tiempo y los residuales.

```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}
library(gridExtra)


grid.arrange(p1, p_tendency,p_res1, p_res1,p_season,p_res2, nrow = 2)
```



## Cereales


Usa el conjunto de datos UScereal (que está en R, en el paquete MASS, ver ?UScereal) para contestar las siguientes preguntas:


### 1. Describe la distribución del contenido de potasio y de fibra de los cereales. ¿Existe o no dispersión suficiente en estos datos para que la elección de cereal pueda tener algún efecto nutricional (busca una tabla de requerimientos mínimos, por ejemplo)?


|Etapa en la vida	|Cantidad recomendada|
|-|-|
|Bebes hasta los 6 meses de edad	400 mg|
|Bebés de 7 a 12 meses|	860 mg|
|Niños de 1 a 3 años|	2,000 mg|
|Niños de 4 a 8 años|	2,300 mg|
|Niños de 9 a 13 años|	2,500 mg|
|Niñas de 9 a 13 años|	2,300 mg|
|Adolescentes de 14 a 18 años (niños )|	3,000 mg|
|Adolescentes de 14 a 18 años (niñas )|	2,300 mg|
|Adultos mayores de 19 años (hombres)|	3,400 mg|
|Adultos mayores de 19 años (mujeres)|	2,600 mg|
|Adolescentes embarazadas|	2,600 mg|
|Mujeres embarazadas|	2,900 mg|
|Adolescentes en periodo de lactancia|	2,500 mg|
|Mujeres en periodo de lactancia|	2,800 mg|

Para consultar la información puede acceder al siguiente link:
https://ods.od.nih.gov/factsheets/Potassium-DatosEnEspanol/

```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}

data<-UScereal

hist(data$potassium, breaks = seq(min(data$potassium), max(data$potassium), length.out =30))
hist(data$fibre,breaks = seq(min(data$fibre), max(data$fibre), length.out =30))

```


Los resultados nos resultan interesante al entender lo que aportan a la ingesta diaria de potasio y de fibra. 


* Primeramente, respecto al potasio lo que observamos es que en realidad la mayoría de los cereales no están aportando mucho a la ingesta diaria. Solamente 3 cereales son los que podemos argumentar están aportando significativamente a la ingesta (los tres son de la marca All-Bran). Esto lo podemos interpretar pensando en que, a menos que elijas alguno de esos tres cereales “outliers”, la elección de cereal no es relevante en cuanto al potasio necesario al día. En 


*En segundo lugar analizando la cantidad de fibra observamos que los cereales sí aportan de manera significativa en la ingesta de fibra. Esto lo podemos argumentar ya que, de la muestra, mínimo siete están aportando aproximadamente un tercio de la dosis diaria.


Fuente consultada para la ingesta deseable de fibra:
https://www.gob.mx/salud/articulos/cuanta-fibra-dietetica-se-debe-consumir#:~:text=Por%20eso%2C%20el%20comit%C3%A9%20de,de%20fibra%20diet%C3%A9tica%20al%20d%C3%ADa.


### 2. Divide los cereales en tres grupos, según los cuantiles 1/3 y 2/3 del contenido de proteína. Grafica pequeños múltiplos para describir la relación entre potasio y fibra para cada uno de los tres grupos. ¿Se trata de la misma relación en cada grupo? ¿En qué son diferentes? ¿Cómo describirías los cereales del grupo con menos contenido de proteína (ve qué cereales son)?

```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center}


v1<-quantile(data$protein,probs = c(1/3,2/3))

data <-data %>% mutate(prot_group= ifelse(protein <= v1[1],1,
                                          ifelse(protein <= v1[2],2,3)))


graph<-function(data2,bins){

hist(data2$potassium, breaks = seq(min(data$potassium), max(data$potassium), length.out =bins))
hist(data2$fibre,breaks = seq(min(data$fibre), max(data$fibre), length.out =bins))
 
  
}

graph(data %>% filter(prot_group==1) ,20)
graph(data %>% filter(prot_group==2) ,20)
graph(data %>% filter(prot_group==3) ,20)


```


Concluimos que estamos cerca del valor que nos permite decir que se observa una relación lineal.


## Pruebas de hipótesis

Nos solicitan hacer un análisis con el objetivo de probar un material nuevo para suela de zapatos (el material B) y ver si es comparable con el material que se usa normalmente (el material A). 

Nos dan el siguiente conjunto de datos:

```{r , echo=T, eval=F,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center''}
zapatos <- read.csv("datos/zapatos-1.csv")
zapatos
```

### 1. Realiza una prueba de hipótesis visual y describe tus conclusiones (cuál es el nivel de significancia de la prueba?).


Para este ejercicio hemos decidido hacer una prueba de permutación visual


```{r , echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center}
#Creo una funcion para replicar cada permutación y graficarla
perms<-function(){
permutations<-zapatos %>% 
  mutate(material=sample(c(1,2), n(), prob =c(.5,.5), replace=T))
permutations$material<-as.factor(permutations$material)
p <- ggplot(permutations, aes(x=material, y=desgaste,fill=material)) + 
  geom_boxplot()  
p+scale_color_manual(values=c( "#E69F00", "#56B4E9"))+ theme(legend.position="none")
}

# Creo la grafica muestral
zapatos$material<-as.factor(zapatos$material)
original<- ggplot(zapatos, aes(x=material, y=desgaste,fill=material)) + 
  geom_boxplot()+scale_color_manual(values=c( "#E69F00", "#56B4E9"))+ theme(legend.position="none")

# Elaboro un grid
grid.arrange(perms(),perms(),perms(),perms(),
             perms(),perms(),perms(),perms(),
             perms(),perms(),perms(),perms(),
             perms(),perms(),perms(),perms(),
             perms(),perms(),original,perms(),nrow =5)

```

De lo que podemos observar en los diferentes diagramas no podemos concluir que es posible rechazar la hipótesis nula. El motivo de esta decisión es que todas parecen provenir de la misma distribución. Además el nivel de significancia de la prueba es muy pequeño (1/20).



### 2. Realiza una prueba de permutaciones para la diferencia de las medias, escribe la hipótesis nula, la hipótesis alterna y tus conclusiones.


Definimos nuestras hipótesis de la siguiente manera:


$$H_o:\mu_1-\mu_2=0$$


$$H_o:\mu_1-\mu_2\neq0$$


```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center} 

# Creo una función de permutaciones para calcular la media
perms<-function(){
permutations<-zapatos %>% 
  mutate(permu=sample(c(1,2), n(), prob =c(.5,.5), replace=T))
  
mean1<-mean((permutations %>% filter(permu==1))$desgaste)
mean2<-mean((permutations %>% filter(permu==2))$desgaste)
mean1-mean2
}

# Corro 200 permutaciones
permutations_dif<-data.frame(sapply(seq_len(200), function(x) perms()))
names(permutations_dif)<-"dif"


#Ahora calculo diferencia de medias de la muestra:
mean1<-mean((zapatos %>% filter(material==1))$desgaste)
mean2<-mean((zapatos %>% filter(material==2))$desgaste)
mean_muestral<-mean1-mean2

# Grafico un histograma con las 200 permutaciones y con rojo marco la media muestral original
ggplot(permutations_dif,aes(x=dif))+
               geom_histogram()+ theme_classic()+ geom_vline(aes(xintercept=mean_muestral),
            color="red", linetype="dashed", size=1)
```


De observar el histograma anterior es evidente que no podemos rechazar la hipótesis nula. El motivo es que la media muestral queda muy cercana al 0 y dentro de la zona de más densidad de la distribución de medias.


### 3. Después de discutir con los responsables del proyecto descubrimos que nos faltaba conocer detalles del proceso generador de datos: el experimento se realizó asignando al azar un material a uno de los zapatos y el otro material al otro zapato de cada niño. ¿Cómo incorporas esta información en la prueba de hipótesis del inciso 2? ¿Cambian tus conclusiones?


Este suceso podríamos decir de forma coloquial que "nos cae como anillo al dedo" debido a que el contrafactual es adecuado (utilizar el otro zapato del mismo niño). Sin embargo, de forma contundente debemos decir que no cambian nuestras conclusiones. Incluso podemos decir que las sostenemos de manera más "fuerte", ya que, los argumentos que tenemos para no rechazar la hipótesis nula vienen del diseño experimental.


## Bootstrap

### Estimación

En este ejercicio realizarás la estimación de la [consulta popular 2021](https://ine.mx/conteo-rapido-consulta-popular-2021/). Para ello 
necesitarás:

* Cómputos [aquí](https://computos.cp2021.ine.mx/votos-distrito/mapa)

* Muestra del conteo rápido usada en la estimación [aquí](https://ine.mx/conteo-rapido-consulta-popular-2021/)

```{r, echo=T, eval=F,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}

muestra <- read_delim("https://ine.mx/wp-content/uploads/2021/08/Conteos-ConsPop21-Lista-MuestraCalculo.txt", delim = "|", skip = 1) 
muestra_tidy <- muestra %>% 
  mutate(
    ID_ESTADO = str_pad(ID_ESTADO, 2, pad = "0"),
    SECCION = str_pad(SECCION, 4, pad = "0"),
    ID_CASILLA = str_pad(ID_CASILLA, 2, pad = "0"),
    ID = str_c(ID_ESTADO, SECCION, TIPO_CASILLA, ID_CASILLA)
    ) %>%  
  group_by(ESTRATO) %>% 
  mutate(n = n()) %>%  
  ungroup()

computos <- read_delim("datos/20210802-2130_INE-CONSULTA-POPULAR-2021/20210802-2130_COMPUTOS-INE-CP2021.csv", 
    delim = "|", escape_double = FALSE, trim_ws = TRUE, quote = "\'",
    skip = 5)
computos <- computos %>%  
  rename(ID = CLAVE_MRCP) %>%  
  mutate(ESTRATO = str_c(str_pad(ID_ENTIDAD, 2, pad = "0"), 
                         str_pad(ID_DISTRITO_FEDERAL, 2, pad = "0")),
         LISTA_NOMINAL = LISTA_NOMINAL_MRCP, 
         TOTAL = TOTAL_OPINIONES) %>% filter(TOTAL_OPINIONES>0)#%>%  
 # group_by(ESTRATO) %>% 
 # mutate(n = n()) %>%  
 # ungroup()
```

### 1. Utiliza el estimador de razón combinado para estimar el voto en favor de cada opción (sí/no/nulos).


```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center}
# A partir de la muestra:
# No uso weights
survey_sample <- muestra_tidy %>% 
    as_survey_design(ids = ID,  strata = "ESTRATO") %>% 
  mutate(p_si=SI/TOTAL,
         p_no=NO/TOTAL,
         p_nulo=NULOS/TOTAL)

estadisticos_sample<-survey_sample %>%
  summarize_at(vars(p_si, p_no,p_nulo), ~survey_mean(.))
estadisticos_sample
```


### 2. Utiliza bootstrap para construir intervalos del 95% de confianza. Compara la longitud de los 3 intervalos y describe que observas.

```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}
# A partir de la muestra:
set.seed(1111)
intervalos_bootsrap<-
  survey_sample %>% 
    as_survey_rep(type = "subbootstrap", replicates = 500) %>%
  srvyr::summarise(p_si = survey_mean(p_si, vartype =  "ci"),
                   p_no = survey_mean(p_no, vartype =  "ci"),
                   p_nulo = survey_mean(p_nulo, vartype =  "ci"))


#Intervalos
intervalos_bootsrap

# Longitud de intervalo SI
intervalos_bootsrap[3]-intervalos_bootsrap[2]
# Longitud de intervalo NO
intervalos_bootsrap[6]-intervalos_bootsrap[5]
# Longitud de intervalo NULO
intervalos_bootsrap[9]-intervalos_bootsrap[8]

```

Los resultados son bastante contundentes e interesantes. Primeramente sale a relucir que hay una mayoría aplastante del SI. En segundo lugar, tenemos al NO y por último la opción del NULO. Como comentario adicional, nos resulta llamativo los resultados que nos dieron en cuanto a la longitud de los intervalos. Por una parte, los intervalos del SI y del NULO son similares en tamaño y se podría decir que en cierta forma un poco más amplios que el del NO. Para nosotros el intervalo asociado al NO nos resalta que sea muy pequeño/poco amplio.


### 3. ¿Tus intervalos contienen los valores observados  en los cómputos? Explica los resultados observados.


```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}

survey_population <- computos %>% 
    as_survey_design(ids = ID, strata = "ESTRATO") %>% 
  mutate(p_si=OPINION_SI/TOTAL_OPINIONES,
         p_no=OPINION_NO/TOTAL_OPINIONES,
         p_nulo=NULOS/TOTAL_OPINIONES)

estadisticos_pop<-survey_population %>%
  summarise(p_si = survey_mean(p_si,na.rm = T),
            p_no = survey_mean(p_no,na.rm = T),
            p_nulo = survey_mean(p_nulo,na.rm = T))
estadisticos_pop
```


Lo que podemos concluir es que en realidad solamente el intervalo del NO contiene a su estimador. Es interesante debido a que, de hecho, era el más acotado de todos.


## Calibración


Selecciona al menos 50 muestras del mismo tamaño y con el mismo diseño que la muestra utilizada en el conteo rápido. Esto es, selecciona el mismo número de casillas, usando muestreo aleatorio simple dentro de cada estrato.


```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}

# Primer paso, creo el codigo para recrear cada muestra estratificada
#Creo catalogo de estrato y n
strata_catalogue <- muestra_tidy %>%
  group_by(ESTRATO) %>%
  sample_n(size=1) %>% dplyr::select(ESTRATO,n)
#Agrego n a computo
computos<-merge(computos,strata_catalogue, by="ESTRATO")

```


```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}
#Creo el código para recrear 1 muestra
# si corro esto 50 veces obtengo 50 muestras
stratified <- computos %>%
  group_by(ESTRATO) %>%
  sample_n(size=n,replace = T)

```


### Para cada muestra calcula un intervalo del 95% de confianza usando bootstrap.


```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}

crea_muestra_e_intervalo_bootrsap<-function(){
#Creo el codigo para recrear 1 muestra
stratified <- computos %>%
  group_by(ESTRATO) %>%
  sample_n(size=n,replace = T)

survey_sample <- stratified %>% 
    as_survey_design(ids = ID,  strata = "ESTRATO") %>% 
  mutate(p_si=OPINION_SI/TOTAL_OPINIONES,
         p_no=OPINION_NO/TOTAL_OPINIONES,
         p_nulo=NULOS/TOTAL_OPINIONES)

intervalos_bootsrap<-
  survey_sample %>% 
  #Usamos solo 50 replicates para no tardar tanto
    as_survey_rep(type = "subbootstrap", replicates = 50) %>%
  srvyr::summarise(p_si = survey_mean(p_si, vartype =  "ci"),
                   p_no = survey_mean(p_no, vartype =  "ci"),
                   p_nulo = survey_mean(p_nulo, vartype =  "ci"))
intervalos_bootsrap
}

intervalos_muestras<-data.frame(sapply(seq_len(50), function(x) crea_muestra_e_intervalo_bootrsap()))
intervalos_muestras<-as.data.frame(t(intervalos_muestras)) %>% mutate(id=row_number())
intervalos_muestras[1:10] <- sapply(intervalos_muestras[1:10],as.numeric)
kable(intervalos_muestras)
```


### Grafica los intervalos y calcula la proporción de ellos que contienen el verdadero valor observado. Describe tus observaciones (evalúa la calibración, compara con el intervalo obtenido en el ejercicio anterior).


```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}

# Proporción SI
ggplot(intervalos_muestras, aes(id,p_si)) + 
  geom_point() +
  geom_errorbar(aes(ymin = p_si_low, ymax = p_si_upp))+ geom_hline(aes(yintercept=estadisticos_pop$p_si),
            color="blue", linetype="dashed", size=1)

#Proporcion
p<-intervalos_muestras[1:3] %>% 
  mutate(dentro=ifelse(estadisticos_pop$p_si>p_si_low &estadisticos_pop$p_si<p_si_upp,1,0 ))
sum(p$dentro)/nrow(intervalos_muestras)

```


```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}

# Proporción NO
ggplot(intervalos_muestras, aes(id,p_no)) + 
  geom_point() +
  geom_errorbar(aes(ymin = p_no_low, ymax = p_no_upp))+ geom_hline(aes(yintercept=estadisticos_pop$p_no),
            color="blue", linetype="dashed", size=1)

#Proporcion
p<-intervalos_muestras[4:6] %>% 
  mutate(dentro=ifelse(estadisticos_pop$p_no>p_no_low &estadisticos_pop$p_no<p_no_upp,1,0 ))
sum(p$dentro)/nrow(intervalos_muestras)

```


```{r, echo=T,message=FALSE,warning=FALSE,out.width = "70%",fig.align = 'center'}

# Proporción NULO
ggplot(intervalos_muestras, aes(id,p_nulo)) + 
  geom_point() +
  geom_errorbar(aes(ymin = p_nulo_low, ymax = p_nulo_upp))+ geom_hline(aes(yintercept=estadisticos_pop$p_nulo),
            color="blue", linetype="dashed", size=1)

#Proporcion
p<-intervalos_muestras[7:9] %>% 
  mutate(dentro=ifelse(estadisticos_pop$p_nulo>p_nulo_low &estadisticos_pop$p_nulo<p_nulo_upp,1,0 ))
sum(p$dentro)/nrow(intervalos_muestras)

```

Reflexión: Para que realmente podamos pensar que estos intervalos sean útiles y contengan al estimador la mayoría de las veces, debemos aceptar que deben ser más “amplios”. Durante el ejercicio anterior nos sucedió que no se estaba capturando a dos de los tres estadísticos. Esto fue así debido a que el intervalo de confianza está ajustado con un valor-p del 0.05 estableciendo con ello intervalos muy estrechos.